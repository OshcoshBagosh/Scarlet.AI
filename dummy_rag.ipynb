{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-08T18:55:41.901976Z",
     "start_time": "2025-10-08T18:55:41.898609Z"
    }
   },
   "source": [
    "# imports\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ],
   "outputs": [],
   "execution_count": 159
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T18:55:41.914321Z",
     "start_time": "2025-10-08T18:55:41.911408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "GEN_MODEL = \"google/flan-t5-base\"\n",
    "COLLECTION = \"campus_dummy\"\n",
    "TOP_K = 3"
   ],
   "id": "cc6b66559c7edbc5",
   "outputs": [],
   "execution_count": 160
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T18:55:44.040230Z",
     "start_time": "2025-10-08T18:55:41.922255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load models\n",
    "embedder = SentenceTransformer(EMBED_MODEL)\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(GEN_MODEL)\n",
    "gen  = AutoModelForSeq2SeqLM.from_pretrained(GEN_MODEL)"
   ],
   "id": "3769d175373b800f",
   "outputs": [],
   "execution_count": 161
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T18:55:44.071835Z",
     "start_time": "2025-10-08T18:55:44.069194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set up simple in-memory store (no external DB). We'll compute embeddings\n",
    "# for all docs and perform cosine similarity search with NumPy.\n",
    "index_ready = False"
   ],
   "id": "a4ef61a0dd2f6410",
   "outputs": [],
   "execution_count": 162
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T18:55:44.082998Z",
     "start_time": "2025-10-08T18:55:44.079105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# input dummy data\n",
    "docs, ids, metadatas = [], [], []\n",
    "with open(\"dummy_corpus.jsonl\", \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        obj = json.loads(line)\n",
    "        docs.append(obj[\"text\"])\n",
    "        ids.append(obj[\"id\"])\n",
    "        metadatas.append({\"title\": obj[\"title\"], \"url\": obj[\"url\"]})"
   ],
   "id": "40c40b91563bbf45",
   "outputs": [],
   "execution_count": 163
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T18:55:44.126650Z",
     "start_time": "2025-10-08T18:55:44.089322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# compute the embeddings (torch tensors to avoid numpy dependency inside Torch)\n",
    "embs = embedder.encode(\n",
    "    docs,\n",
    "    normalize_embeddings=True,\n",
    "    convert_to_numpy=False,\n",
    "    convert_to_tensor=True\n",
    ")\n",
    "# ensure embeddings are on CPU for similarity and indexing\n",
    "embs = embs.detach().cpu()\n",
    "# mark index as ready\n",
    "index_ready = True"
   ],
   "id": "21abe462c6b6a278",
   "outputs": [],
   "execution_count": 164
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T18:55:44.136253Z",
     "start_time": "2025-10-08T18:55:44.133598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# style guide and few-shot example\n",
    "STYLE_GUIDE = \"\"\"\\\n",
    "You are Campus Assistant. Answer in one short sentence, present tense, and conversational tone.\n",
    "Do not hedge (avoid \"it seems\", \"likely\"). Do not include citations in the sentence.\n",
    "If a date exists, write it as \"January 12\" (Month Day). If semester context appears in sources, include it.\n",
    "If the question begins with 'why', state one clear reason from the sources.\n",
    "Example:\n",
    "Q: When is the Add/Drop deadline?\n",
    "A: The add/drop deadline is January 12 for the Spring semester.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "FEW_SHOT = \"\"\"\\\n",
    "Q: Where do I find advising?\n",
    "A: You can meet with advising in the Academic Advising Center during posted hours.\n",
    "\"\"\""
   ],
   "id": "419cce18231e0548",
   "outputs": [],
   "execution_count": 165
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T18:55:44.144952Z",
     "start_time": "2025-10-08T18:55:44.142054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# regex patterns for rule-based answer generation\n",
    "DATE_PAT = re.compile(r\"\\b(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|\"\n",
    "                      r\"Jul(?:y)?|Aug(?:ust)?|Sep(?:t(?:ember)?)?|Oct(?:ober)?|Nov(?:ember)?|\"\n",
    "                      r\"Dec(?:ember)?)\\s+\\d{1,2}\\b\", re.IGNORECASE)\n",
    "SEMESTER_PAT = re.compile(r\"\\b(Spring|Summer|Fall|Winter)\\b\", re.IGNORECASE)\n",
    "ADD_DROP_PAT = re.compile(r\"(add/?drop|drop/?add)\", re.IGNORECASE)\n",
    "ADVISING_PAT = re.compile(r\"\\b(advis(e|ing)|advisor|advisors?)\\b\", re.IGNORECASE)"
   ],
   "id": "2984a1a6d71d211f",
   "outputs": [],
   "execution_count": 166
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T18:55:44.165889Z",
     "start_time": "2025-10-08T18:55:44.151686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# helpers\n",
    "\n",
    "# retrieve top-k relevant documents\n",
    "def retrieve(query: str, k: int = TOP_K):\n",
    "    q_emb = embedder.encode(\n",
    "        [query],\n",
    "        normalize_embeddings=True,\n",
    "        convert_to_numpy=False,\n",
    "        convert_to_tensor=True\n",
    "    )[0].detach().cpu()\n",
    "    # cosine similarity since embeddings are normalized\n",
    "    sims = (embs @ q_emb).detach().cpu()\n",
    "    k = min(k, sims.shape[0])\n",
    "    values, indices = torch.topk(sims, k)\n",
    "    hits = []\n",
    "    for rank, (score, i) in enumerate(zip(values.tolist(), indices.tolist())):\n",
    "        hits.append({\n",
    "            \"id\": ids[int(i)],\n",
    "            \"text\": docs[int(i)],\n",
    "            \"metadata\": metadatas[int(i)],\n",
    "            \"score\": float(score)\n",
    "        })\n",
    "    return hits\n",
    "# build prompt from question and contexts (black-box)\n",
    "def build_prompt(question: str, contexts: list[dict], max_ctx_chars: int = 1200) -> str:\n",
    "    ctx = []\n",
    "    used = 0\n",
    "    for i, c in enumerate(contexts):\n",
    "        t = f\"[{i+1}] {c['text']}\".strip()\n",
    "        if used + len(t) > max_ctx_chars:\n",
    "            break\n",
    "        ctx.append(t)\n",
    "        used += len(t)\n",
    "\n",
    "    ctx_block = \"\\n\\n\".join(ctx)\n",
    "    prompt = (\n",
    "        STYLE_GUIDE + \"\\n\" +\n",
    "        FEW_SHOT + \"\\n\" +\n",
    "        \"Answer ONLY using the information in these sources. If unsure, say: \"\n",
    "        \"\\\"I’m not sure based on the sources provided.\\\"\"\n",
    "        \"\\n\\n\"\n",
    "        f\"Question: {question}\\n\\n\"\n",
    "        f\"Sources:\\n{ctx_block}\\n\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def confidence_label(best_score: float) -> str:\n",
    "    if best_score >= 0.60: return \"High\"\n",
    "    if best_score >= 0.40: return \"Medium\"\n",
    "    return \"Low\"\n",
    "\n",
    "def try_rule_assist_advising(question: str, contexts: list[dict]):\n",
    "    if not contexts:\n",
    "        return None\n",
    "    top = contexts[0][\"text\"]\n",
    "    if ADVISING_PAT.search(question) or ADVISING_PAT.search(top):\n",
    "        m = re.search(r\"should (.+?)(?:\\.|$)\", top, re.IGNORECASE)\n",
    "        if m:\n",
    "            reason = m.group(1).strip()\n",
    "            return f\"You should meet with advising to {reason}.\"\n",
    "        return \"You should meet with advising to plan your classes before the registration window opens.\"\n",
    "    return None\n",
    "\n",
    "# generate answer from prompt\n",
    "def generate_answer(question: str):\n",
    "    contexts = retrieve(question, k=TOP_K)\n",
    "\n",
    "    # compute best score first (for logging + confidence label)\n",
    "    best_score = contexts[0][\"score\"] if contexts else 0.0\n",
    "    print(f\"[debug] best_score={best_score:.3f}\")\n",
    "    conf = confidence_label(best_score)\n",
    "\n",
    "    # try rule-based answers first (so they're not blocked by low-confidence)\n",
    "    rule_ans = try_rule_assist(question, contexts) or try_rule_assist_advising(question, contexts)\n",
    "    if rule_ans:\n",
    "        ans = rule_ans.strip()\n",
    "        if not ans.endswith(\".\"): ans += \".\"\n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"answer\": ans,\n",
    "            \"retrieved\": contexts,\n",
    "            \"confidence\": conf,\n",
    "            \"citations\": [{\"title\": c[\"metadata\"][\"title\"], \"url\": c[\"metadata\"][\"url\"]} for c in contexts]\n",
    "        }\n",
    "\n",
    "    # low-confidence guard (after rules)\n",
    "    LOW_CONF_THRESHOLD = 0.35  # relaxed for small corpora\n",
    "    if best_score < LOW_CONF_THRESHOLD:\n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"answer\": \"I’m not sure based on the sources provided. Please check the official registrar page.\",\n",
    "            \"retrieved\": contexts,\n",
    "            \"confidence\": conf,\n",
    "            \"citations\": [{\"title\": c[\"metadata\"][\"title\"], \"url\": c[\"metadata\"][\"url\"]} for c in contexts]\n",
    "        }\n",
    "\n",
    "\n",
    "    if rule_ans:\n",
    "        ans = rule_ans.strip()\n",
    "        if not ans.endswith(\".\"): ans += \".\"\n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"answer\": ans,\n",
    "            \"retrieved\": contexts,\n",
    "            \"confidence\": conf,\n",
    "            \"citations\": [{\"title\": c[\"metadata\"][\"title\"], \"url\": c[\"metadata\"][\"url\"]} for c in contexts]\n",
    "        }\n",
    "\n",
    "    # model-backed answer\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\" #gpu's on colab if needed\n",
    "    gen.to(device)\n",
    "    prompt = build_prompt(question, contexts)\n",
    "    inputs = tok(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "    outputs = gen.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=512,\n",
    "        num_beams=1,\n",
    "        do_sample=False,\n",
    "        length_penalty=0.1,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    answer = tok.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "    if not answer.endswith(\".\"):\n",
    "        answer += \".\"\n",
    "\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"answer\": answer,\n",
    "        \"retrieved\": contexts,\n",
    "        \"confidence\": conf,\n",
    "        \"citations\": [{\"title\": c[\"metadata\"][\"title\"], \"url\": c[\"metadata\"][\"url\"]} for c in contexts]\n",
    "    }"
   ],
   "id": "edf81b8ebfb6c339",
   "outputs": [],
   "execution_count": 167
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T18:57:10.057701Z",
     "start_time": "2025-10-08T18:57:09.048508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# so black-box baseline is query -> retrieve -> generate_answer\n",
    "if __name__ == \"__main__\":\n",
    "    q = \"How do I know what classes to take?\"\n",
    "    out = generate_answer(q)\n",
    "    print(\"Q:\", out[\"question\"])\n",
    "    print(\"A:\", out[\"answer\"])\n",
    "    print(\"\\n-- Retrieved Contexts --\")\n",
    "    for i, c in enumerate(out[\"retrieved\"], 1):\n",
    "        print(f\"[{i}] {c['metadata']['title']} | {c['metadata']['url']}\")\n",
    "        print(\"   \", c[\"text\"])"
   ],
   "id": "48c6ed7ccb757782",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[debug] best_score=0.335\n",
      "Q: How do I know what classes to take?\n",
      "A: You should meet with advising to meet advisors to plan classes before the registration window opens.\n",
      "\n",
      "-- Retrieved Contexts --\n",
      "[1] Advising FAQ | https://example.edu/advising\n",
      "    Students should meet advisors to plan classes before the registration window opens.\n",
      "[2] Financial Aid | https://example.edu/aid\n",
      "    FAFSA priority filing date is November 1.\n",
      "[3] Registrar Deadlines | https://example.edu/registrar\n",
      "    Drop/add ends January 12 for the Spring term.\n"
     ]
    }
   ],
   "execution_count": 173
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-08T18:55:44.711503Z",
     "start_time": "2025-10-08T18:55:44.708872Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "16957b7697ccf6aa",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
